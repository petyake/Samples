{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Automobile Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read automobile data csv file\n",
    "\n",
    "path = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\n",
    "df = pd.read_csv(path, header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the headers since they are stored in a separate file\n",
    "\n",
    "# create headers list\n",
    "\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "print(\"headers\\n\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the headers and recheck the dataframe\n",
    "\n",
    "df.columns = headers\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data types of variables in the dataframe\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View summary statistics for each variable, include sring/object variables\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# replace \"?\" with NaN in variables\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of missing values in each variable\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing values with the average of the given variable:\n",
    "\n",
    "fillna = [\"normalized-losses\", \"bore\", \"stroke\", \"horsepower\", \"peak-rpm\", \"price\"]\n",
    "\n",
    "for series in fillna:\n",
    "    series_avg = df[series].astype('float').mean(axis=0)\n",
    "    df[series].replace(np.nan, series_avg, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For variable num-of-doors, replace missings with the most frequent value 'four' shown in the descriptives\n",
    "\n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that no missings are left\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisit data types and descriptives to identify strings/objects for conversion to numeric\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric variables saved as string/object to numeric \n",
    "\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"bore\", \"stroke\", \"horsepower\", \"peak-rpm\", \"price\"]] = df[[\"bore\", \"stroke\", \"horsepower\", \"peak-rpm\", \"price\"]].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify conversion\n",
    "\n",
    "print(df.dtypes)\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binning select variables\n",
    "\n",
    "# Convert to needed format: from float to integer\n",
    "\n",
    "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of horsepower to determine bin sizes\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "plt.pyplot.hist(df[\"horsepower\"])\n",
    "\n",
    "# set x/y labels and title\n",
    "\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 bins of equal size, i.e, there are 4 dividers that are cut-off values for the bins. \n",
    "# Store the cut-off points in array \"bins\"\n",
    "\n",
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
    "print(bins)\n",
    "\n",
    "# Name the bins\n",
    "\n",
    "group_names = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign bins to horsepower values with the 'cut' function\n",
    "\n",
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
    "df[['horsepower','horsepower-binned']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View number of autos in each bin\n",
    "\n",
    "df[\"horsepower-binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bins in a histogram\n",
    "\n",
    "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
    "\n",
    "# set x/y labels and title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the continuous variables \n",
    "\n",
    "df_cont = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first non-normalized variable \n",
    "\n",
    "plt.pyplot.plot(df['normalized-losses'])\n",
    "plt.pyplot.ylabel('normalized losses')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the continuous variables/columns\n",
    "\n",
    "df_cont.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all continous vars in the list\n",
    "\n",
    "to_norm = ['symboling', 'normalized-losses', 'wheel-base', 'length', 'width',\n",
    "       'height', 'curb-weight', 'engine-size', 'bore', 'stroke',\n",
    "       'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
    "       'highway-mpg', 'price']\n",
    "\n",
    "for series in to_norm:\n",
    "    df[series] = df[series] / df[series].max() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify variables are on normalized scale\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of first normalized variable shows the same dynamics as above, now on the rescaled Y-axis\n",
    "\n",
    "plt.pyplot.plot(df['normalized-losses'])\n",
    "plt.pyplot.ylabel('normalized losses')\n",
    "plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dichotomize Categorical Variables into Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the categorical variables\n",
    "\n",
    "df_cat = df.select_dtypes(include=['object'])\n",
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummies from categorical variables of interest\n",
    "\n",
    "df_d1= pd.get_dummies(df['make'])\n",
    "df_d2= pd.get_dummies(df['fuel-type'])\n",
    "df_d3= pd.get_dummies(df['num-of-doors'])\n",
    "df_d4= pd.get_dummies(df['body-style'])\n",
    "df_d5= pd.get_dummies(df['engine-type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge the main dataframe with the new dummy variable dataframes\n",
    "\n",
    "df = pd.concat([df, df_d1, df_d2, df_d3, df_d4, df_d5], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data to Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pair-wise correlations of each feature with target variable price\n",
    "\n",
    "corr_list = df[df.columns[1:]].corr()['price'][:]\n",
    "corr_table = pd.DataFrame(corr_list)\n",
    "\n",
    "# Sort the correlations\n",
    "\n",
    "corr_table_s = corr_table.sort_values(by='price', ascending=False)\n",
    "\n",
    "# View top 5 positively correlated features\n",
    "\n",
    "corr_table_s.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top 5 negatively correlated features\n",
    "\n",
    "corr_table_s.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually examine top correlated features and price in scatter plots  \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "to_scatter = ['engine-size', 'curb-weight', 'horsepower', 'width', 'length', 'highway-mpg', 'city-mpg']\n",
    "\n",
    "for series in to_scatter:\n",
    "    x = df[series]\n",
    "    y = df[\"price\"]\n",
    "    plt.pyplot.scatter(x, y)\n",
    "    plt.pyplot.xlabel(series)\n",
    "    plt.pyplot.ylabel(\"price\")\n",
    "    plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take logs of top features and price; \n",
    "\n",
    "df['engine-size_l'] = np.log(df['engine-size'])\n",
    "df['curb-weight_l'] = np.log(df['curb-weight'])\n",
    "df['horsepower_l'] = np.log(df['horsepower'])\n",
    "df['width_l'] = np.log(df['width'])\n",
    "df['length_l'] = np.log(df['length'])\n",
    "df['highway-mpg_l'] = np.log(df['highway-mpg'])\n",
    "df['city-mpg_l'] = np.log(df['city-mpg'])\n",
    "df['price_l'] = np.log(df['price'])\n",
    "\n",
    "# Plot the log features with log of price; plots show linearity in logs\n",
    "\n",
    "to_scatter = ['engine-size_l', 'curb-weight_l', 'horsepower_l', 'width_l', 'length_l', 'highway-mpg_l', 'city-mpg_l']\n",
    "\n",
    "for series in to_scatter:\n",
    "    x = df[series]\n",
    "    y = df[\"price_l\"]\n",
    "    plt.pyplot.scatter(x, y)\n",
    "    plt.pyplot.xlabel(series)\n",
    "    plt.pyplot.ylabel(\"price_l\")\n",
    "    plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculate linear correlations with p-values for statistical significance for top features in logs\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "selected_features = ['engine-size_l', 'curb-weight_l', 'horsepower_l', 'width_l', 'length_l', 'highway-mpg_l', 'city-mpg_l']\n",
    "\n",
    "for series in selected_features:\n",
    "\n",
    "    pearson_coef, p_value = stats.pearsonr(df[series], df['price_l'])\n",
    "    print(\"The Pearson Correlation of log of price with \", series, \"is \", round(pearson_coef,4), \" with P-value =\", round(p_value,4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Matrix for top features to check for multicollinearity.\n",
    "\n",
    "corr_list = df[['engine-size_l', 'curb-weight_l', 'horsepower_l', 'highway-mpg_l', 'city-mpg_l']]\n",
    "\n",
    "corr = corr_list.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# result: drop city-mpg_l since it's too strongly correlated with highway-mpg_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Explore Bivariate Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the visualization package: seaborn\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Regression Plots (i.e, scatter plots with fitted lines)\n",
    "\n",
    "to_regplots = ['engine-size_l', 'curb-weight_l', 'horsepower_l', 'highway-mpg_l']\n",
    "\n",
    "for series in to_regplots:\n",
    "    width = 6\n",
    "    height = 4\n",
    "    plt.pyplot.figure(figsize=(width, height))\n",
    "    sns.regplot(x=df[series], y=df['price_l'], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Residual Plots (should be evenly distributed around zero)\n",
    "\n",
    "to_resplots = ['engine-size_l', 'curb-weight_l', 'horsepower_l', 'highway-mpg_l']\n",
    "\n",
    "for series in to_resplots:\n",
    "    width = 6\n",
    "    height = 4\n",
    "    plt.pyplot.figure(figsize=(width, height))\n",
    "    sns.residplot(df[series], df['price_l'])\n",
    "    plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The above results show that the feature curb-weight_l should be dropped from the model.\n",
    "# This is because the residuals suggest that curb-weight_l is not explaining auto prices well, \n",
    "    #i.e. the residuals are not randomly scattered around zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Multiple Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on final selected features with strongest linear relationship with price\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "X = df[['engine-size_l', 'horsepower_l', 'highway-mpg_l']]\n",
    "\n",
    "lm.fit(X, df['price_l'])\n",
    "\n",
    "\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Auto Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict, i.e, Calculate auto prices using the regression equation\n",
    "\n",
    "Y_hat = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot of Actual vs Predicted Prices\n",
    "\n",
    "plt.pyplot.figure(figsize=(width, height))\n",
    "\n",
    "\n",
    "ax1 = sns.distplot(df['price_l'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(Y_hat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "\n",
    "plt.pyplot.title('Actual vs Fitted Values for Log Price')\n",
    "plt.pyplot.xlabel('Price (in logs)')\n",
    "plt.pyplot.ylabel('Proportion of Cars')\n",
    "\n",
    "plt.pyplot.show()\n",
    "plt.pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the R^2\n",
    "\n",
    "print('The R-square is: ', lm.score(X, df['price_l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find MSE (Mean Squared Error), i.e, error between calculated/predicted and actual target Price\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('The mean square error of log price and predicted log price using multifit is: ', \\\n",
    "      mean_squared_error(df['price_l'], Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place target data in separate dataframe\n",
    "\n",
    "y_data = df['price_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Y target data from X data\n",
    "\n",
    "x_data=df.drop('price_l', axis=1)\n",
    "x_data=df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.30, random_state=1)\n",
    "\n",
    "\n",
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the train data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lre=LinearRegression()\n",
    "\n",
    "lre.fit(x_train[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R^2 of model on train data\n",
    "\n",
    "lre.score(x_train[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test data\n",
    "\n",
    "lre.fit(x_test[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R^2 of model on test data\n",
    "\n",
    "lre.score(x_test[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results show that selected model fits both train and test data equally well, \n",
    "  # i.e., model is stable without initial signs of overfitting;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in 4 folds (cv=4) and calculate R^2 for each fold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Rcross = cross_val_score(lre, x_data[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_data, cv=4)\n",
    "\n",
    "Rcross\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean of the folds is\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model Fit on Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train[['engine-size_l', 'horsepower_l', 'highway-mpg_l']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = lr.predict(x_train[['engine-size_l', 'horsepower_l', 'highway-mpg_l']])\n",
    "yhat_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = lr.predict(x_test[['engine-size_l', 'horsepower_l', 'highway-mpg_l']])\n",
    "yhat_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 6\n",
    "    height = 4\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Price (in logs)')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution Plot of Predicted vs Actual Price (in Logs) Using Training Data'\n",
    "DistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title='Distribution Plot of Predicted vs Actual Price (in Logs) Using Test Data'\n",
    "DistributionPlot(y_test, yhat_test, \"Actual Values (Test)\", \"Predicted Values (Test)\", Title)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results show that the model performs relatively well on the test data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# End of File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
